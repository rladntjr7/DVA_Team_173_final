{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0d424edf-d21c-4524-a8aa-af462dfd3f34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "backend    models     packages.txt  requirements.txt  toy_data\n",
      "data_full  notebooks  readme.MD     src\n"
     ]
    }
   ],
   "source": [
    "!ls ../../.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3608b7e8-673b-4fb0-8beb-53ee0de074d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ginger/code/gderiddershanghai/DVA_Team_173/notebooks/ginger/bert_finetune\n"
     ]
    }
   ],
   "source": [
    "!pwd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "06511111-ad40-4ce3-913c-ab0e17daa9a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TweetNormalizer.py  ner_bert_finetune.py    tweet_bert_finetune.py\n",
      "__init__.py\t    sentiment_extractor.py\n"
     ]
    }
   ],
   "source": [
    "!ls /home/ginger/code/gderiddershanghai/DVA_Team_173/src/data_processing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1d4c5cb4-3ebd-4aa9-8fa7-f5280da5b22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/ginger/code/gderiddershanghai/DVA_Team_173/src/data_processing')\n",
    "from TweetNormalizer import normalizeTweet\n",
    "import torch\n",
    "from transformers import AutoModel, AutoTokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ce69d669-4767-4a07-98fc-7cf0721b37b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Print Testing Dont buy apple stock it fucking sucks ass . Totally regret :crying_face:\n"
     ]
    }
   ],
   "source": [
    "line = normalizeTweet(\"Dont buy apple stock it fucking sucks ass. Totally regret ðŸ˜¢\")\n",
    "print(\"Print Testing\", line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ac899cbc-2e94-4e2c-8d0e-24a936ac2c09",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"vinai/bertweet-large\", use_fast=False)\n",
    "inputs = tokenizer(line, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "572e6f15-22a6-4368-8e0f-612990c9c41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a28b3290-ccfd-4747-9bb6-0e1d82f5919c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ginger/.pyenv/versions/3.10.6/lib/python3.10/site-packages/huggingface_hub/file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/ginger/.pyenv/versions/3.10.6/lib/python3.10/site-packages/huggingface_hub/file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e5c746578dd4f9b893dfc47e46ca50b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/1.42G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at vinai/bertweet-large were not used when initializing RobertaModel: ['lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.decoder.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at vinai/bertweet-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "bertweet = AutoModel.from_pretrained(\"vinai/bertweet-large\",  force_download=True)\n",
    "with torch.no_grad():\n",
    "    features = bertweet(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6d6fcff5-4b98-4fa0-a338-b17aa957b584",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[-0.1719, -0.1180,  0.0072,  ...,  0.3427, -0.1545,  0.1675],\n",
       "         [ 0.1453, -0.0441, -0.5463,  ...,  0.4314, -0.1737, -0.1021],\n",
       "         [-0.0815,  0.2577, -0.2071,  ..., -0.2722,  0.7567,  0.0446],\n",
       "         ...,\n",
       "         [ 0.1495,  0.4980, -1.1285,  ...,  0.7866, -0.1691, -0.0682],\n",
       "         [-0.0889, -0.1233, -0.0038,  ...,  0.6608, -0.1318, -0.3417],\n",
       "         [ 0.0326,  0.0120, -0.0344,  ..., -0.0257,  0.1176,  0.0033]]]), pooler_output=tensor([[ 0.2350, -0.0783, -0.2313,  ...,  0.4911,  0.3300, -0.1254]]), hidden_states=None, past_key_values=None, attentions=None, cross_attentions=None)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
